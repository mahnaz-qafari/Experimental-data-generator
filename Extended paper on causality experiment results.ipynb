{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8abdfc2",
   "metadata": {},
   "source": [
    "# Random causal structure generator\n",
    "Here the goal is to generate data based on known random DAGs.\n",
    "\n",
    "The steps are as follows:\n",
    "- generate random DAG (causal structure)\n",
    "- genrate a data based on the DAG\n",
    "- generate an event log\n",
    "\n",
    "The generated data is for the experimaental results of the following [paper](https://arxiv.org/pdf/2108.07795.pdf):\n",
    "\n",
    "Qafari MS, van der Aalst W. Feature Recommendation for Structural Equation Model Discovery in Process Mining. arXiv preprint arXiv:2108.07795. 2021 Aug 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f60025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "import pandas as pd\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from pm4py.objects.log.obj import EventLog, Trace, Event\n",
    "from datetime import datetime, timedelta\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random DAG with k nodes\n",
    "def random_DAG(name, mapping):\n",
    "    num = 0\n",
    "    while len(mapping.keys())!=num:\n",
    "        G=nx.gnp_random_graph(len(mapping.keys()),0.5,directed=True)\n",
    "        DAG = nx.DiGraph([(u,v,{'weight':random.randint(1,10)}) for (u,v) in G.edges() if u<v-1])\n",
    "        nx.is_directed_acyclic_graph(DAG)\n",
    "        num = DAG.number_of_nodes()\n",
    "    DAG = nx.relabel_nodes(DAG, mapping)\n",
    "    save_and_visualize_image(DAG,name)\n",
    "\n",
    "    return DAG\n",
    "\n",
    "def save_and_visualize_image(G,name):\n",
    "    nx.draw(G, with_labels = True)\n",
    "    plt.savefig(name+\".png\", format=\"PNG\")\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the graph\n",
    "def visualize_graph(G):\n",
    "    net = Network(notebook=True)\n",
    "    net.from_nx(G)\n",
    "    net.show(\"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the parents on node t\n",
    "def ancestors(G, n):\n",
    "    return G.pred[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_int_list(min_val, max_val, length):\n",
    "    l = []\n",
    "    for i in range(0, length):\n",
    "        n = random.randint(min_val, max_val)\n",
    "        l.append(n)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa02b92",
   "metadata": {},
   "source": [
    "In the following cell, you can change the noise and coefficient intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ece6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the column of items for sources\n",
    "mins = 0 # min_source_variable\n",
    "maxs = 20 # max_source_variable\n",
    "def generate_data_source_node(length):\n",
    "    min_max = rand_int_list(mins, maxs, 2)\n",
    "    while min_max[0]>=min_max[1]:\n",
    "        min_max = rand_int_list(mins, maxs, 2) \n",
    "    return rand_int_list(min_max[0], min_max[1], length)\n",
    "\n",
    "# generate the column of items for non source features\n",
    "# steps that need to be taken:\n",
    "# 1- find the parents\n",
    "# 2- generate noise list\n",
    "# 3- generate coefficents\n",
    "# 4- compute the linear equation\n",
    "min_noise = -5\n",
    "max_noise = 5\n",
    "min_coeff = -5\n",
    "max_coeff = 5\n",
    "def generate_data_non_source_node(G, node, length, column_dict, coeffInfo):\n",
    "    min_max = rand_int_list(min_noise, max_noise, 2)\n",
    "    # noise vector\n",
    "    while min_max[0]>=min_max[1]:\n",
    "        min_max = rand_int_list(min_noise, max_noise, 2)\n",
    "    noise = rand_int_list(min_max[0], min_max[1], length)  \n",
    "    values = noise\n",
    "    node_list=[]\n",
    "    for itam in G.predecessors(node):\n",
    "        node_list.append(itam)\n",
    "    for item in node_list:\n",
    "        coeff = random.randint(min_coeff, max_coeff)\n",
    "        while (coeff <= 1) & (coeff >= -1):\n",
    "            coeff = random.randint(min_coeff, max_coeff)\n",
    "        source = str(item)\n",
    "        sink = str(node)\n",
    "        coeff_str = str(coeff)\n",
    "        coeffInfo += (source + \" --> \" + sink + \" : \" + coeff_str + '\\n')\n",
    "        temp_list = [i * coeff for i in column_dict[item]] \n",
    "        values = list( map(add, values, temp_list) )\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f9f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate m datasets\n",
    "# n : the number of event logs to generate\n",
    "# m : the number of features in each event log --> use an even number bigger than 2\n",
    "def generate_all_data(n, m, coeffInfo):\n",
    "    for i in range(0, n):\n",
    "        fileName = \"data\" + str(i)\n",
    "        coeffInfo += ('Data '+ 'i' + '\\n')\n",
    "        coeffInfo += ('first component' + '\\n')\n",
    "        data1 = generate_data(1000, fileName + 'part_1', create_mapping(m//2, 'A'), coeffInfo) \n",
    "        coeffInfo += 'second component' + '\\n'\n",
    "        data2 = generate_data(1000, fileName + 'part_2', create_mapping(m//2, 'B'), coeffInfo)\n",
    "        data = pd.concat([data1, data2], axis=1, join=\"inner\")\n",
    "        data.to_csv(fileName+'.txt', index=False, line_terminator= '\\n', sep = '\\t')\n",
    "        xes_exporter.apply(convert_to_event_log(data), 'eventlog_'+ str(i) + '.xes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one dataset with respect to the given DAG\n",
    "def generate_data_one_DAG(G, length, coeffInfo):\n",
    "    column_dict={}\n",
    "    for node in list((list(nx.topological_sort(G)))):\n",
    "        if G.in_degree(node)==0:\n",
    "            column_dict[node] = generate_data_source_node(length)\n",
    "        elif G.in_degree(node)>0:\n",
    "            l = generate_data_non_source_node(G, node, length, column_dict, coeffInfo)\n",
    "            column_dict[node] = l      \n",
    "    return pd.DataFrame.from_dict(column_dict,orient='index').transpose()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512fd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(length, file_name, mapping, coeffInfo): \n",
    "    data = pd.DataFrame() \n",
    "    G = random_DAG('G_'+ file_name, mapping)\n",
    "    data = data.append(generate_data_one_DAG(G, length, coeffInfo), ignore_index=True)\n",
    "    record_info(file_name, G, data)\n",
    "       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac61a50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data set to event log\n",
    "# convert to proper format \n",
    "# -- add activity name\n",
    "# -- add timestamp\n",
    "def change_format(data):\n",
    "    act_names = [\"start\", \"end\"]\n",
    "    timestamp = datetime.datetime.now()\n",
    "    log_tabular = []\n",
    "    for case_id in range(0, len(data)):\n",
    "        event = data.iloc[case_id].values.flatten().tolist()\n",
    "        for act_name in act_names:\n",
    "            event.append(act_name)\n",
    "            event.append(timestamp) #.timestamp())\n",
    "            event.append(case_id)\n",
    "            log_tabular.append(event.copy())\n",
    "            timestamp = timestamp + datetime.timedelta(days=0.1)\n",
    "            event = data.iloc[case_id].values.flatten().tolist()\n",
    "            \n",
    "    col_names = data.columns.tolist()\n",
    "    col_names.append('concept:name')\n",
    "    col_names.append('time:timestamp')\n",
    "    col_names.append('case:concept:name')\n",
    "    log_tabular = pd.DataFrame(log_tabular, columns=col_names)   \n",
    "    log_tabular = dataframe_utils.convert_timestamp_columns_in_df(log_tabular)\n",
    "    return log_converter.apply(log_tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features divided by two\n",
    "# name : feature name (e.g., name = \"A\" nad n = 5, then the feature names would be {A_0, A_1, A_2, A_3, A_4})\n",
    "def create_mapping(n, name):\n",
    "    mapping = dict()\n",
    "    for i in range(0, n):\n",
    "        mapping[i] = name + str(i)\n",
    "        \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b270a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record the information of the generated eventlogs. \n",
    "# data is recorded in \n",
    "def ancestor_writer(G, file_name):\n",
    "    dir_name = file_name + '/' + file_name + \"_ancestors.txt\"\n",
    "    ancestors = \"Ancestors: \\n\"\n",
    "    for node in G.nodes():\n",
    "        ancestors = ancestors + node + \"\\n\"\n",
    "        ancestors = ancestors + str(G.pred[node]) + \"\\n\"\n",
    "    text_file = open(dir_name, \"w\")\n",
    "    text_file.write(ancestors)\n",
    "    text_file.close()    \n",
    "    \n",
    "def record_info(file_name, graph, data):\n",
    "    Path(file_name).mkdir(parents=True, exist_ok=True)\n",
    "    dir_name = file_name + '/' + file_name + \".txt\"\n",
    "    nx.write_edgelist(graph, dir_name)\n",
    "    dir_name = file_name + '/' + file_name + \".png\"\n",
    "    nx.draw(graph, with_labels = True)\n",
    "    plt.savefig(dir_name, format=\"PNG\")\n",
    "    plt.clf()\n",
    "    dir_name = file_name + '/' + file_name + \".csv\"\n",
    "    data.to_csv(dir_name, index=False, line_terminator= '\\n')\n",
    "    ancestor_writer(graph, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d346b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_event_log(data):\n",
    "    L = EventLog()\n",
    "    time = datetime.now()\n",
    "    columns = data.columns.values.tolist()\n",
    "    for index, row in data.iterrows():\n",
    "        e1 = Event()\n",
    "        e1[\"concept:name\"] = \"A\"\n",
    "        time = time + timedelta(seconds=300)\n",
    "        e1[\"time:timestamp\"] = time\n",
    "        e2 = Event()\n",
    "        e2[\"concept:name\"] = \"B\"\n",
    "        time = time + timedelta(seconds=600)\n",
    "        e2[\"time:timestamp\"] = time\n",
    "        t = Trace()\n",
    "        t.append(e1)\n",
    "        t.append(e2)\n",
    "        for att in columns:\n",
    "            # Python typing is required in the current release\n",
    "            t.attributes[att] = float(row[att])\n",
    "        L.append(t)   \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63159686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 10 event logs each with 30 features\n",
    "\n",
    "coeffInfo = \"coefficients:\\n\"\n",
    "generate_all_data(10, 20, coeffInfo)\n",
    "\n",
    "with open(\"coeffInfo.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"%s\" % coeffInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adecfba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
